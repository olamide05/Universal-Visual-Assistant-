# Universal Visual Assistant (UVA)

**A conversational AI app for image analysis and secure file sharing.**

UVA uses AI to analyze images (objects, text, charts) and supports secure file uploads (images, PDFs) with shareable links and AI summaries. The MVP includes:
- Object recognition (e.g., identify a bag, get brand/price).
- File uploads to AWS S3 with shareable links.
- Basic chatbot for image result discussions.

Built with **Python**, **Flask**, and **CLIP (Hugging Face)**, UVA targets e-commerce, education, and SMBs in 2025â€™s AI boom (36% CAGR).

## ğŸš€ Getting Started
### Prerequisites
- Python 3.9+
- Git
- AWS CLI (for file sharing)

### Installation
1. Clone: `git clone https://github.com/olamide05/Universal-Visual-Assistant-.git`
2. Activate venv: `source venv/bin/activate`
3. Install: `pip install -r requirements.txt`
4. Run: `python app.py` and visit `http://localhost:5000`

## ğŸ›  Tech Stack
- Backend: Flask (Python)
- AI: CLIP (Hugging Face) for images, PyPDF2 for PDFs
- Storage: AWS S3
- Future: Docker, AWS ECS, WebRTC for P2P

## ğŸ¤ Contributing
Fork, branch (`feature/your-feature`), commit, push, PR. See [CONTRIBUTING.md](CONTRIBUTING.md).

## ğŸ“¬ Feedback
Open an issue or DM on X (@olamide4real_).

## ğŸ“„ License
MIT License.

**Built by Olamide in 2025.**
